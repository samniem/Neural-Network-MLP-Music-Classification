{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification Using MLP Neural Network\n",
    "\n",
    "Classify music by genres ranging from rock and blues to classical. The data has 264 features and 4363 songs selected from the Million Song Dataset. For the MLP classifier two accuracy metrics are used: classification accuracy and log-loss for each genre. The music genres used for the data set are\n",
    "1. Pop_Rock, 2. Electronic, 3. Rap, 4. Jazz, 5. Latin, 6. RnB, 7. International, 8. Country, 9. Reggae and 10. Blues.\n",
    "\n",
    "## Libraries and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4363, 264)\n",
      "Training labels shape: (4363, 1)\n",
      "\n",
      "---Label counts---\n",
      "Label 1 = [2178.]\n",
      "Label 2 = [618.]\n",
      "Label 3 = [326.]\n",
      "Label 4 = [253.]\n",
      "Label 5 = [214.]\n",
      "Label 6 = [260.]\n",
      "Label 7 = [141.]\n",
      "Label 8 = [195.]\n",
      "Label 9 = [92.]\n",
      "Label 10 = [86.]\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('train_data.csv',header=None)\n",
    "label = np.array(pd.read_csv('train_labels.csv', header=None))\n",
    "label = np.subtract(label,1)\n",
    "\n",
    "print(\"Training data shape:\", x.shape)\n",
    "print(\"Training labels shape:\", label.shape)\n",
    "print(\"\\n---Label counts---\")\n",
    "label_count = np.zeros((10,1))\n",
    "for i in range(label.shape[0]):\n",
    "        label_count[label[i]] += 1\n",
    "for i in range(0,10):\n",
    "    print(\"Label\", i+1,\"=\"  , label_count[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Principal component analysis (PCA) has been chosen to remove redundant information from the data set. The data is first normalized with Sklearn's standard scaler followed by calculating eigenvalues $\\lambda$ and eigenvectors.\n",
    "Figure 1 below shows the total explained variance of the principal components. The first 40 principal components explain approximately 81% of the total variance and the first 175 principal components explain about 99.2% of the total variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after eigenvector transformation\n",
      "(4363, 175)\n"
     ]
    }
   ],
   "source": [
    "#standard scaling and eigenvalues\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(x)\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(cov_mat)\n",
    "\n",
    "#Calculate and plot explained variance\n",
    "total = sum(eigen_values)\n",
    "variance_exp = [(i / total) for i in sorted(eigen_values, reverse=True)]\n",
    "cum_var_exp = np.cumsum(variance_exp)\n",
    "plt.bar(range(1,265), variance_exp, alpha=0.5, align='center',label='individual explained variance')\n",
    "plt.step(range(1,265), cum_var_exp, where='mid', label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.plot(40,0.81,'X')\n",
    "plt.plot(175,0.992,'X')\n",
    "plt.show()\n",
    "\n",
    "#Transform data by eigenvectors\n",
    "w = eigen_vectors[:,0:175]\n",
    "X_pca = X_std.dot(w)\n",
    "print(\"Shape of X after eigenvector transformation\")\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split\n",
    "\n",
    "The labels are unevenly distributed so using stratified shuffle split to keep the correct label ratios for training and test data sets. Test data set size is 25 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (3272, 175)\n",
      "Training labels shape: (3272, 1)\n",
      "\n",
      "---Label counts---\n",
      "Label 1 = [1633.]\n",
      "Label 2 = [463.]\n",
      "Label 3 = [244.]\n",
      "Label 4 = [190.]\n",
      "Label 5 = [161.]\n",
      "Label 6 = [195.]\n",
      "Label 7 = [106.]\n",
      "Label 8 = [146.]\n",
      "Label 9 = [69.]\n",
      "Label 10 = [65.]\n",
      "\n",
      "Test data shape: (1091, 175)\n",
      "Test labels shape: (1091, 1)\n",
      "\n",
      "---Label counts---\n",
      "Label 1 = [545.]\n",
      "Label 2 = [155.]\n",
      "Label 3 = [82.]\n",
      "Label 4 = [63.]\n",
      "Label 5 = [53.]\n",
      "Label 6 = [65.]\n",
      "Label 7 = [35.]\n",
      "Label 8 = [49.]\n",
      "Label 9 = [23.]\n",
      "Label 10 = [21.]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "sss = StratifiedShuffleSplit(n_splits = 2, test_size = 0.25, \n",
    "                             random_state=0)\n",
    "for train_index, test_index in sss.split(X_pca, label):\n",
    "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"\\n---Label counts---\")\n",
    "label_count = np.zeros((10,1))\n",
    "for i in range(y_train.shape[0]):\n",
    "        label_count[y_train[i]] += 1\n",
    "for i in range(0,10):\n",
    "    print(\"Label\", i+1,\"=\"  , label_count[i])\n",
    "    \n",
    "print(\"\\nTest data shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)\n",
    "print(\"\\n---Label counts---\")\n",
    "label_count = np.zeros((10,1))\n",
    "for i in range(y_test.shape[0]):\n",
    "        label_count[y_test[i]] += 1\n",
    "for i in range(0,10):\n",
    "    print(\"Label\", i+1,\"=\"  , label_count[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "A multilayer perceptron (MLP) is an artificial neural network that can be split to three parts: input layer, hidden layer and output layer. MLP is a feedforward network that is utilized for supervised learning through backpropagation. The MLP implementation uses sigmoid activation function\n",
    "$$s = \\frac{1}{1+e^{-x}}$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetMLP(object):\n",
    "    def __init__(self, n_output, n_features, n_hidden=30, l1=0.0,\n",
    "                l2=0.0, epochs=500, eta=0.001, alpha=0.0,\n",
    "                decrease_const=0.0, shuffle=True, minibatches=1,\n",
    "                random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_output = n_output\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.w1, self.w2 = self._initialize_weights()\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        \n",
    "    def _encode_labels(self, y, k):\n",
    "        onehot = np.zeros((k, y.shape[0]))\n",
    "        for idx, val in enumerate(y):\n",
    "            onehot[val, idx] = 1.0\n",
    "        return onehot\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        w1 = np.random.uniform(-1.0, 1.0, \n",
    "                                   size=self.n_hidden*(self.n_features+1))\n",
    "        w1 = w1.reshape(self.n_hidden, self.n_features +1)\n",
    "        w2 = np.random.uniform(-1.0, 1.0, \n",
    "                                   size=self.n_output*(self.n_hidden +1))\n",
    "        w2 = w2.reshape(self.n_output, self.n_hidden + 1)\n",
    "        return w1, w2\n",
    "        \n",
    "    def _sigmoid(self, z):\n",
    "        return 1.0/(1.0 + np.exp(-z))\n",
    "        \n",
    "    def _sigmoid_gradient(self, z):\n",
    "        sg = self._sigmoid(z)\n",
    "        return sg * (1 - sg)\n",
    "        \n",
    "    def _add_bias_unit(self, X, how='column'):\n",
    "        if how == 'column':\n",
    "            X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "            X_new[:, 1:] = X\n",
    "        elif how == 'row':\n",
    "            X_new = np.ones((X.shape[0]+1,X.shape[1]))\n",
    "            X_new[1:, :] = X\n",
    "        else:\n",
    "            raise AttributeError('How must be col or row')\n",
    "        return X_new\n",
    "            \n",
    "    def _feedforward(self, X, w1, w2):\n",
    "        a1 = self._add_bias_unit(X, how='column')\n",
    "        z2 = w1.dot(a1.T)\n",
    "        a2 = self._sigmoid(z2)\n",
    "        a2 = self._add_bias_unit(a2, how='row')\n",
    "        z3 = w2.dot(a2)\n",
    "        a3 = self._sigmoid(z3)\n",
    "        return a1, z2, a2, z3, a3\n",
    "        \n",
    "    def _L2_reg(self, lambda_, w1, w2):\n",
    "        return (lambda_/2.0) * (np.sum(w1[:, 1:] ** 2)\\\n",
    "                                   + np.sum(w2[:, 1:] ** 2))\n",
    "    def _L1_reg(self, lambda_, w1, w2):\n",
    "        return (lambda_/2.0) * (np.abs(w1[:, 1:].sum())\\\n",
    "                                   + np.abs(w2[:, 1:].sum()))\n",
    "        \n",
    "    def _get_cost(self, y_enc, output, w1, w2):\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1 - y_enc) * np.log(1 - output)\n",
    "        cost = np.sum(term1 - term2)\n",
    "        L1_term = self._L1_reg(self.l1, w1, w2)\n",
    "        L2_term = self._L2_reg(self.l2, w1, w2)\n",
    "        cost = cost + L1_term + L2_term\n",
    "        return cost\n",
    "        \n",
    "    def _get_gradient(self, a1, a2, a3, z2, y_enc, w1, w2):\n",
    "        sigma3 = a3 - y_enc\n",
    "        z2 = self._add_bias_unit(z2, how='row')\n",
    "        sigma2 = w2.T.dot(sigma3) * self._sigmoid_gradient(z2)\n",
    "        sigma2 = sigma2[1:, :]\n",
    "        grad1 = sigma2.dot(a1)\n",
    "        grad2 = sigma3.dot(a2.T)\n",
    "            \n",
    "        grad1[:, 1:] += (w1[:, 1:] * (self.l1 + self.l2))\n",
    "        grad2[:, 1:] += (w2[:, 1:] * (self.l1 + self.l2))\n",
    "        return grad1, grad2\n",
    "        \n",
    "    def predict(self, X):\n",
    "        a1, z2, a2, z3, a3 = self._feedforward(X, self.w1, self.w2)\n",
    "        print(\"z3 shape:\", z3.shape)\n",
    "        y_pred = np.argmax(z3, axis=0)\n",
    "        return y_pred, z3\n",
    "        \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        self.cost_ = []\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        y_enc = self._encode_labels(y, self.n_output)\n",
    "            \n",
    "        delta_w1_prev = np.zeros(self.w1.shape)\n",
    "        delta_w2_prev = np.zeros(self.w2.shape)\n",
    "            \n",
    "        for i in range(self.epochs):\n",
    "            self.eta /= (1+ self.decrease_const*i)\n",
    "            if  print_progress:\n",
    "                print(\"Epoch:\", i+1, self.epochs)\n",
    "            if self.shuffle:\n",
    "                idx = np.random.permutation(y_data.shape[0])\n",
    "                X_data, y_enc = X_data[idx], y_enc[:, idx]\n",
    "                    \n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            for idx in mini:\n",
    "                a1, z2, a2, z3, a3 = self._feedforward(X_data[idx], self.w1, self.w2)\n",
    "                cost = self._get_cost(y_enc=y_enc[:, idx], output=a3, w1=self.w1,w2=self.w2)\n",
    "                self.cost_.append(cost)\n",
    "                    \n",
    "                grad1, grad2 = self._get_gradient(a1=a1, a2=a2, a3=a3, z2=z2, y_enc=y_enc[:, idx],\n",
    "                                                     w1=self.w1,w2=self.w2)\n",
    "                delta_w1, delta_w2 = self.eta * grad1, self.eta * grad2\n",
    "                self.w1 -= (delta_w1 + (self.alpha * delta_w1_prev))\n",
    "                self.w2 -= (delta_w2 + (self.alpha * delta_w2_prev))\n",
    "                delta_w1_prev, delta_w2_prev = delta_w1, delta_w2\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetMLP(n_output=10, n_features=X_pca.shape[1],n_hidden=150,\n",
    "                 l2=0.1,l1=0.05, epochs=3000, eta=0.001, alpha=0.001,\n",
    "                 decrease_const=0.00001, shuffle=True,\n",
    "                 minibatches=50,random_state=1)\n",
    "nn.fit(X_train, y_train, print_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(nn.cost_)), nn.cost_)\n",
    "plt.ylim([0, 2000])\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs * 50')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = np.array_split(range(len(nn.cost_)), 1000)\n",
    "cost_ary = np.array(nn.cost_)\n",
    "cost_avgs = [np.mean(cost_ary[i]) for i in batches]\n",
    "plt.plot(range(len(cost_avgs)), cost_avgs, color='red')\n",
    "plt.ylim([0,500])\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y, y_hat):\n",
    "    N = y.shape[0];\n",
    "    correct = 0;\n",
    "    for i in range(N):\n",
    "        if (y[i] == y_hat[i]):\n",
    "            correct += 1\n",
    "    accuracy = round(correct/N,4)*100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred, probabilities = nn.predict(X_test)\n",
    "accuracy = calculate_accuracy(y_test, y_test_pred)\n",
    "print(\"Prediction shape:\",y_test_pred.shape)\n",
    "logloss = np.transpose(probabilities)\n",
    "scaler = MinMaxScaler(copy=True, feature_range=(0,1))\n",
    "logloss = scaler.fit_transform(logloss)\n",
    "print(\"Probabilities shape:\", logloss.shape,\"\\n\")\n",
    "print(\"Labeling accuracy\")\n",
    "print(accuracy)\n",
    "\n",
    "print(\"\\n---Label counts---\")\n",
    "label_count2 = np.zeros((10,1))\n",
    "for i in range(y_test_pred.shape[0]):\n",
    "        label_count2[y_test_pred[i]] += 1\n",
    "for i in range(0,10):\n",
    "    print(\"Label\", i+1,\"=\"  , label_count2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log loss:\")\n",
    "print(log_loss(y_test, probabilities.T))\n",
    "print(\"\\nConfusion matrix:\")\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "[1] Sklearn. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "[2] Lay, D. Lay. S, McDonald, J. Linear Algebra and its Applications. 5th Ed. Harlow, England: Pearson, 2016. ISBN 978-1-292-09223-2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
